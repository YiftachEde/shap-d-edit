{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee5b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "None is the location\n",
      "None is the location\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3a1d7682734bb3bbb772d6d2750b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents, sample_latents_noised\n",
    "# from shap_e.diffusion.gaussian_diffusion import ddim_inversion\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config,GaussianDiffusion\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "xm = load_model('transmitter', device=device)\n",
    "model = load_model('text300M', device=device)\n",
    "diffusion = diffusion_from_config(load_config('diffusion'))\n",
    "batch_size = 16\n",
    "guidance_scale = 12.5\n",
    "prompt = \"a billiard table\"\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(texts=[prompt] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=2,\n",
    ")\n",
    "if hasattr(model, \"cached_model_kwargs\"):\n",
    "    model_kwargs = model.cached_model_kwargs(batch_size, dict(texts=[prompt] * batch_size))\n",
    "pass\n",
    "\n",
    "\n",
    "\n",
    "# latents_noised = diffusion.ddim_inversion(model=model,cond=model_kwargs['embeddings'],latent=latents,clip_denoised=True,model_kwargs=model_kwargs)\n",
    "# print(latents_noised.shape)\n",
    "# latents = ddim_inversion(latents,\n",
    "                        #  model, diffusion, progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8631189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1024 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:32<00:00, 31.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# diffusion = GaussianDiffusion(betas = torch.linspace(0.0009,0.0120,1000),model_mean_type=diffusion.model_mean_type,model_var_type=diffusion.model_var_type,loss_type=diffusion.loss_type,discretized_t0=diffusion.discretized_t0,channel_scales=diffusion.channel_scales,channel_biases=diffusion.channel_biases)\n",
    "latents_noised = diffusion.ddim_inversion(model=model,latent=latents,clip_denoised=True, model_kwargs=dict(texts=[prompt] * batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57405cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_new = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale*10,\n",
    "    model_kwargs=dict(texts=[\"a rainbow colored shark\"] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=False,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=20,\n",
    "    s_churn=0,\n",
    "    noise=latents_noised[300]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_new_2 = sample_latents_noised(\n",
    "    latent=latents_noised[100],\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(texts=[\"a re\"] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=False,\n",
    "    use_fp16=True,\n",
    "    use_karras=False,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2d2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570db04f12304b74a89287bedfad006c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fr6+vLy8eLi4srJyKqjoziAPQ5/HA5+HA1/HA…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.17s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57b12da09ad45548691b41ddac75109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fr6+vHx8d3d3Lm4uJyhp4uVoIaOl2uLejGINx…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3099c540e3423a8e99fc1990ff4ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fb29uzs7OTk5NnZ2MXEw52ZljB6NxB4HRB3HA…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbde633429f44d19b3af309bb4f7037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fr6+vT09O3t7eHg4MvLyqekozaJPhiHHBiGHB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:08,  2.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ef27a7c59948b991ef2bba2ecb3960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/ff39+vr68PAwKCfnJaSjnqYfFmRXjaOPh6LKB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  2.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f386f79df5c24e26a19ef0644d9def14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/vz8/Pf39+rq6tra2czLyqyppzKAQAV9GwN8GRJ7Ig…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:12,  2.17s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d0d77213ab42569f35465f2716f374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/vz8/Pj4+PDw8N7d3c/Nz8C9vqKcmyqHOxSFJhGCIg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:15,  2.19s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa55efbf3d334e08974dd9e6eb635680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v7+/f39/fz8/Pj4+Ozs7M7Ozbi5sK+voqarmaCjk5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:17,  2.19s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a3d4af176e4cd1a3a0d2d074bed126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fv7+/b29uzs7M7OzLC1qpyZlG2XaDKLNiGGJh…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:19,  2.17s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11971da916f74f53b34f8094ce5896db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fz8/Pf39+jn58jJyK6uq3mkiHuQei2URCeJMx…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:21,  2.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f4fea368b1412ea4b00bf3f5149a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fv7+/f39vDw8OXl5c7NzLKkonWWiBGMNwyNMw…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:23,  2.17s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dc2a5c856941bea508c16d93185cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fn5+fb29vPz8+/v7+Xl5cXEw4GSgzeRWjaIUi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:25,  2.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05582d35abc4ec2ac0b9dea6b3ae60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAIAAocAAP////7+/v39/fv7+/j4+O3s7MnIyKako4WSioOFgG2DelKDYR…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:28,  2.19s/it]"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "       # Example of saving the latents as meshes.\n",
    "from shap_e.util.notebooks import decode_latent_mesh\n",
    "render_mode = 'stf' # you can change this to 'stf'\n",
    "size = 512 # this is the size of the renders; higher values take longer to render.\n",
    "from tqdm import tqdm\n",
    "cameras = create_pan_cameras(size, device)\n",
    "# latents_noised\n",
    "im = []\n",
    "with torch.no_grad():\n",
    "    for i, latent in tqdm(enumerate(latents)):\n",
    "                # decoder_output = decode_latent_images(xm, latent_code.float(), cameras, rendering_mode='stf')\n",
    "        # arr = decoder_output.clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "        # images = [Image.fromarray(x) for x in arr]\n",
    "\n",
    "        # print(latent)\n",
    "        decoder_output = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "        arr = decoder_output.clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "        images = [Image.fromarray(x) for x in arr]\n",
    "\n",
    "        im += images\n",
    "        display(gif_widget(images))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d690c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diffusion.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "967e8816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6049b4ba11524850ab183cd7eaad1157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diffusion = diffusion_from_config(load_config('diffusion'))\n",
    "# diffusion.betas = diffusion.betas[:200]\n",
    "diffusion.num_timesteps = 200\n",
    "diffusion.alphas_cumprod = diffusion.alphas_cumprod[:200]\n",
    "latents_new = sample_latents(\n",
    "    batch_size=2,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(texts=[\"a coffee table\"] * 2),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    "    noise=torch.cat((latents_noised[200],latents_noised[200]),dim=0)\n",
    ")\n",
    "\n",
    "                        # Example of saving the latents as meshes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e163a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1f8a5eeb994c11ad6af86d170ccd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAEAAYcAAFk9KVk9KFg9Klg9KVk8KFg8KVg8KFc8KVc8KFY8KVc7KFc7J1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:41, 41.09s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d887d45bf36c4d9a9c43572203247d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhAAEAAYcAAFk9KVk9KFg9Klg9KVk8KFg8KVg8KFc8KVc8KFY8KVc7KFc7J1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:22, 41.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from shap_e.util.notebooks import decode_latent_mesh\n",
    "render_mode = 'nerf' # you can change this to 'stf'\n",
    "size = 256 # this is the size of the renders; higher values take longer to render.\n",
    "from tqdm import tqdm\n",
    "cameras = create_pan_cameras(size, device)\n",
    "# latents_noised\n",
    "im = []\n",
    "for i, latent in tqdm(enumerate(latents_new[:2])):\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    im += images\n",
    "    display(gif_widget(images))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # Example of saving the latents as meshes.\n",
    "from shap_e.util.notebooks import decode_latent_mesh\n",
    "render_mode = 'nerf' # you can change this to 'stf'\n",
    "size = 128 # this is the size of the renders; higher values take longer to render.\n",
    "from tqdm import tqdm\n",
    "cameras = create_pan_cameras(size, device)\n",
    "# latents_noised\n",
    "im = []\n",
    "for i, latent in tqdm(enumerate(latents_noised[1022:])):\n",
    "    print(latent)\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    im += images\n",
    "    display(gif_widget(images))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7eac24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2453c92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fvcore in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: numpy in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore) (1.26.3)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore) (0.1.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore) (4.65.0)\n",
      "Requirement already satisfied: termcolor>=1.1 in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore) (2.1.0)\n",
      "Requirement already satisfied: Pillow in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore) (9.3.0)\n",
      "Requirement already satisfied: tabulate in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from iopath) (2.3.0)\n",
      "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py310_cu121_pyt210/download.html\n",
      "Collecting pytorch3d\n",
      "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py310_cu121_pyt210/pytorch3d-0.7.5-cp310-cp310-linux_x86_64.whl (20.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fvcore in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from pytorch3d) (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from pytorch3d) (0.1.9)\n",
      "Requirement already satisfied: numpy in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore->pytorch3d) (1.26.3)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore->pytorch3d) (0.1.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore->pytorch3d) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore->pytorch3d) (4.65.0)\n",
      "Requirement already satisfied: termcolor>=1.1 in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore->pytorch3d) (2.1.0)\n",
      "Requirement already satisfied: Pillow in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore->pytorch3d) (9.3.0)\n",
      "Requirement already satisfied: tabulate in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from fvcore->pytorch3d) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /home/yiftach/anaconda3/envs/instantmesh/lib/python3.10/site-packages (from iopath->pytorch3d) (2.3.0)\n",
      "Installing collected packages: pytorch3d\n",
      "Successfully installed pytorch3d-0.7.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "version_str=\"\".join([\n",
    "    f\"py3{sys.version_info.minor}_cu\",\n",
    "    torch.version.cuda.replace(\".\",\"\"),\n",
    "    f\"_pyt{pyt_version_str}\"\n",
    "])\n",
    "!pip install fvcore iopath\n",
    "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128 # this is the size of the renders; higher values take longer to render.\n",
    "cameras = create_pan_cameras(size, device)\n",
    "# latents_noised\n",
    "im2 = []\n",
    "for i, l2 in tqdm(enumerate(latents_new)):\n",
    "    images = decode_latent_images(xm, l2, cameras, rendering_mode=\"nerf\")\n",
    "    display(gif_widget(images))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d94e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "im[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c707e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = load_model('transmitter', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_new,latents,latents_noised[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = diffusion_from_config(load_config('diffusion'))\n",
    "batch_size = 1\n",
    "guidance_scale = 15.0\n",
    "prompt = \"a panda\"\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(texts=[prompt] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
